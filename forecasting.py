# -*- coding: utf-8 -*-
"""forecasting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Em5ZtOgTHnqOJRkjdxs2mm36dOuQPhlx
"""


"""### Import Libararies/ Modules"""

#!pip install skforecast
#!pip install prophet

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    mean_squared_error as mse,
    mean_absolute_error as mae,
    mean_absolute_percentage_error as mape)
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from xgboost import XGBRegressor
from skforecast.recursive import ForecasterRecursive
from skforecast.preprocessing import RollingFeatures
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
from prophet import Prophet
from itertools import product
import warnings
warnings.filterwarnings('ignore')
pd.set_option('display.float_format', '{:,.2f}'.format)
import logging
logging.getLogger('prophet').setLevel(logging.WARNING)
logging.getLogger('cmdstanpy').disabled = True
import os
import urllib.request

# Download the dataset if it doesn't exist

def download_ts_co():
    url = "https://raw.githubusercontent.com/varunjoshua/ScalerDSML-ProductSalesForecast/main/data/ts_co.csv"
    filename = "ts_co.csv"

    if not os.path.exists(filename):
        print(f"Downloading {filename}...")
        urllib.request.urlretrieve(url, filename)
        print("Download complete.")
    else:
        print(f"{filename} already exists.")

download_ts_co()


# Load the dataset
ts = pd.read_csv('ts_co.csv')
ts.head()

"""# **Pre-processing functions**

## **Function to process data for Regression**
"""

# Function to tranform and process the inference data given
  # The test data provided is ungrouped with records of all stores for each day
  # The data needs to be grouped and transformed for the Recursive Forecasting function
  # The function will group and aggregate the data for Company and Regions : R1, R2, R3, R4

def inference_data_processor(data):
    import pandas as pd
    import numpy as np

    # Step 1: Convert 'Date' to datetime and add 'Discounted_Flag'
    data['Date'] = pd.to_datetime(data['Date'])
    data['Discounted_Flag'] = data['Discount'].apply(lambda x: 1 if x == 'Yes' else 0)

    # Step 2: function to process each group
    def process_group(group_df):
        group_df = group_df.groupby('Date').agg({
            'Holiday': 'last',
            'Discounted_Flag': lambda x: x.sum() / x.count()
        }).rename(columns={'Discounted_Flag': 'Discounted Stores'})

        # Date features
        group_df['Day Count'] = (group_df.index - group_df.index.min()).days
        group_df['Weekend'] = group_df.index.dayofweek.isin([5, 6]).astype(int)
        day_of_week = group_df.index.dayofweek
        month = group_df.index.month

        # Cyclical features
        group_df['Month_sine'] = np.sin(2 * np.pi * month / 12)
        group_df['Month_cosine'] = np.cos(2 * np.pi * month / 12)
        group_df['Day of Week_sine'] = np.sin(2 * np.pi * day_of_week / 7)
        group_df['Day of Week_cosine'] = np.cos(2 * np.pi * day_of_week / 7)

        return group_df

    # Step 3: Create datasets
    inf_all = process_group(data)
    inf_r1 = process_group(data[data['Region_Code'] == 'R1'])
    inf_r2 = process_group(data[data['Region_Code'] == 'R2'])
    inf_r3 = process_group(data[data['Region_Code'] == 'R3'])
    inf_r4 = process_group(data[data['Region_Code'] == 'R4'])

    return inf_all, inf_r1, inf_r2, inf_r3, inf_r4

"""## **Function to process data for SARIMAX**"""

# Function inference_exog_processor will be used to transform and process the inference dataset...
#...and return datframes with exog variable for Company and Regions : R1, R2, R3, R4, for the inference period

def inference_exog_processor(data):

    # Step 1: Convert 'Date' to datetime and add 'Discounted_Flag'
    data['Date'] = pd.to_datetime(data['Date'])
    data['Discounted_Flag'] = data['Discount'].apply(lambda x: 1 if x == 'Yes' else 0)

    # Step 2: function to process each group
    def process_group(group_df):
        group_df = group_df.groupby('Date').agg({
            'Holiday': 'last',
            'Discounted_Flag': lambda x: x.sum() / x.count()
        }).rename(columns={'Discounted_Flag': 'Discounted Stores'})

        return group_df

    # Step 3: Creating datasets
    exog_all = process_group(data)
    exog_r1 = process_group(data[data['Region_Code'] == 'R1'])
    exog_r2 = process_group(data[data['Region_Code'] == 'R2'])
    exog_r3 = process_group(data[data['Region_Code'] == 'R3'])
    exog_r4 = process_group(data[data['Region_Code'] == 'R4'])

    return exog_all, exog_r1, exog_r2, exog_r3, exog_r4

"""## **Function to process data for Prophet**"""

def prophet_data_formatter(data, is_inference=False):

    df = pd.DataFrame()

    if not is_inference:
        df['y'] = data['Sales']

    df['ds'] = pd.to_datetime(data['Date'])
    exog = data.drop(['Date'] + ([] if is_inference else ['Sales']), axis=1)
    df = pd.concat([df, exog.reset_index(drop=True)], axis=1)
    return df

"""# **Model Params**"""

model_params = {
    'Company': {
        'arima_order': (3, 0, 2),
        'sarimax_order': (2, 1, 2),
        'seasonal_order': (1, 0, 2, 7)
    },
    'Region 1': {
        'arima_order': (3, 1, 3),
        'sarimax_order': (2, 1, 1),
        'seasonal_order': (2, 1, 0, 7)
    },
    'Region 2': {
        'arima_order': (3, 1, 3),
        'sarimax_order': (0, 1, 2),
        'seasonal_order': (2, 1, 0, 7)
    },
    'Region 3': {
        'arima_order': (3, 0, 2),
        'sarimax_order': (0, 1, 1),
        'seasonal_order': (2, 1, 0, 7)
    },
    'Region 4': {
        'arima_order': (1, 1, 1),
        'sarimax_order': (2, 1, 2),
        'seasonal_order': (1, 0, 2, 7)
    }
}

print(model_params)

"""# **Recursive Linear Regression Forecasting**"""

#Function performs recursive forecasting using Linear Regression or XGBoost.

#Parameters:
  # df_train: Processed training data (pandas dataframe) with target_col
  # df_inference: Processed inference data (no target_col required)
  # model_type: 'lr' for Linear Regression or 'xgb' for XGBoost
  # target_col: Target variable name (default='Sales')

#Returns:
  # Pandad DataFrame with forecasted Sales for the inference period


def recursive_forecast(df_train, df_inference, model='lr', target_col='Sales'):
    df_train = df_train.copy()
    df_inference = df_inference.copy()

    df_train.index.freq = 'D'
    df_inference.index.freq = 'D'

    y_train = df_train[target_col]
    X_train = df_train.drop(columns=[target_col])
    X_inference = df_inference.drop(columns=[target_col]) if target_col in df_inference.columns else df_inference # if inference used for testing

    max_lag = 31
    window_features = RollingFeatures(
        stats=['mean', 'mean', 'mean'],
        window_sizes=[7, 14, 31]
    )

    if model == 'lr':
        forecaster = ForecasterRecursive(
            regressor=LinearRegression(),
            lags=[1, 2, 3, 7, 31],
            window_features=window_features
        )
    elif model == 'xgb':
        forecaster = ForecasterRecursive(
            regressor=XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42),
            lags=[1, 2, 3, 7, 31]
        )
    else:
        raise ValueError("Invalid model type. Choose 'lr' or 'xgb'.")

    forecaster.fit(y=y_train, exog=X_train)
    y_pred = forecaster.predict(steps=len(df_inference), exog=X_inference, last_window=y_train[-max_lag:])

    df_forecast = df_inference.copy()
    df_forecast['Sales'] = y_pred.values

    return df_forecast

"""# **ARIMA Forecasting**"""

# The arima_forecast function will
  # Train the model on given data using pre-computed best p,d,q order
  # Use model to forecast m steps in the future


def arima_forecast(df_train, m_steps, arima_order=(1, 1, 1), target_col='Sales'):
    df_train = df_train.copy()
    df_train.index.freq = 'D'

    # Fit ARIMA model
    model = ARIMA(df_train[target_col], order=arima_order)
    model_fit = model.fit()

    # Forecast for the inference period
    forecast = model_fit.forecast(steps=m_steps)

    # Prepare output DataFrame
    future_index = pd.date_range(start=df_train.index[-1] + pd.Timedelta(days=1), periods=m_steps, freq='D')
    df_forecast = pd.DataFrame({target_col: forecast}, index=future_index)

    return df_forecast

"""# **SARIMAX Forecasting**"""

# The sarima_forecast function will
  # Train the model on given data using pre-computed best p,d,q,P,D,Q,s order
  # Use model to forecast m steps in the future

def sarimax_forecast(df_train, m_steps, exog_train, exog_pred,
                     order=(1, 1, 1), seasonal_order=(1, 0, 1, 7), target_col='Sales'):

    df_train = df_train.copy()
    exog_train = exog_train.copy()
    exog_pred = exog_pred.copy()

    df_train.index.freq = 'D'
    exog_train.index.freq = 'D'
    exog_pred.index.freq = 'D'

    # Fit SARIMAX on full training data
    model = SARIMAX(df_train[target_col],
                    order=order,
                    seasonal_order=seasonal_order,
                    exog=exog_train)

    model_fit = model.fit(disp=False)

    # Forecast for the inference period
    forecast = model_fit.forecast(steps=m_steps, exog=exog_pred)

    # Prepare output DataFrame
    future_index = pd.date_range(start=df_train.index[-1] + pd.Timedelta(days=1), periods=m_steps, freq='D')
    df_forecast = pd.DataFrame({target_col: forecast}, index=future_index)

    return df_forecast

"""# **Prophet Forecasting**"""

def prophet_forecast(ts_data, test_size, m_steps, exog, exog_pred):
    warnings.filterwarnings("ignore")

    # Step 1: Creating dataframe for Prophet
    df = ts_data.reset_index()
    df.columns = ['ds', 'y']
    df = pd.concat([df, exog.reset_index(drop=True)], axis=1)

    # Split into train and test
    train_df = df[:-test_size]
    test_df = df[-test_size:]

    # Step 2: Fit Prophet Model
    model = Prophet(yearly_seasonality=True, weekly_seasonality=True, changepoint_prior_scale=1.25, seasonality_mode='additive')
    model.add_regressor('Holiday')
    model.add_regressor('Discounted Stores')
    model.add_seasonality(name='monthly', period=30.5, fourier_order=5)
    #model.add_seasonality(name='14day', period=14, fourier_order=5)
    model.fit(train_df)

    # Step 3: Create future dataframe for test
    future_test = test_df[['ds', 'Holiday', 'Discounted Stores']]
    forecast_test = model.predict(future_test)

    # Compute MAPE
    test_mape = mape(test_df['y'], forecast_test['yhat'])
    print(f"\nProphet MAPE on test split: {test_mape:.4f}")

    # Step 4: Plot Test Prediction vs Actual
    plt.figure(figsize=(10, 4))
    plt.plot(test_df['ds'], test_df['y'], label='Actual Test Data')
    plt.plot(test_df['ds'], forecast_test['yhat'], label='Test Prediction', linestyle='--')
    plt.title('Prophet Forecast vs Actual on Test Set')
    plt.xticks(rotation=45)
    plt.legend()
    plt.tight_layout()
    plt.show()

    # Step 5: Forecast Future m Steps using full data
    full_df = df.copy()
    model_full = Prophet(yearly_seasonality=True, weekly_seasonality=True, changepoint_prior_scale=1.25, seasonality_mode='additive')
    model_full.add_regressor('Holiday')
    model_full.add_regressor('Discounted Stores')
    model_full.add_seasonality(name='monthly', period=30.5, fourier_order=5)
    #model_full.add_seasonality(name='14day', period=14, fourier_order=5)
    model_full.fit(full_df)

    # Prepare future df (including exog_pred)
    future_forecast = pd.concat([
        full_df[['ds', 'Holiday', 'Discounted Stores']],
        exog_pred.reset_index(drop=True)
    ], axis=0).tail(m_steps)

    future_dates = pd.date_range(start=ts_data.index[-1] + pd.Timedelta(days=1), periods=m_steps, freq='D')
    future_forecast['ds'] = future_dates
    forecast_future = model_full.predict(future_forecast)

    # Step 6: Plot Full Forecast
    plt.figure(figsize=(10, 4))
    plt.plot(ts_data.index[-100:], ts_data[-100:], label='Last 100 Data Points')
    plt.plot(future_dates, forecast_future['yhat'], label='Forecast from Full Data', linestyle='--')
    plt.title('Prophet Forecast for the Next m Steps')
    plt.xticks(rotation=45)
    plt.legend()
    plt.tight_layout()
    plt.show()

    return forecast_future[['ds', 'yhat']]

"""# **Plot Function**"""

"""
    Plot historical and forecasted sales for a single model.

    Parameters:
    - df_train: DataFrame with 'Sales' and datetime index (training data)
    - df_forecast: DataFrame with 'Sales' and datetime index (forecasted values)
    - model_name: Name of the forecasting model (str)
    - inf_label: Optional label for the plot (e.g., 'Company' or 'Region')
    """

def plot_model_forecast(df_train, df_forecast, model_name, inf_label=''):


    fig, ax = plt.subplots(figsize=(14, 5))

    # Historical data (last 100 days)
    ax.plot(df_train.index[-100:], df_train['Sales'][-100:], label='Historical Sales', color='black')

    # Forecast
    ax.plot(df_forecast.index, df_forecast['Sales'], linestyle='--', label=f'Forecast ({model_name})', color='blue')

    ax.set_title(f"Forecasted Sales for {inf_label} ({model_name})")
    ax.set_xlabel("Date")
    ax.set_ylabel("Sales")
    ax.legend()
    ax.grid(True)
    plt.xticks(rotation=45)
    plt.tight_layout()

    return fig